mmocr_detect/
â”œâ”€ detector/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ config.py          # all knobs live here (model name, device, thresholds, paths)
â”‚  â””â”€ runner.py          # small â€œDetectTextâ€ class that wraps MMOCR and postprocess
â”œâ”€ scripts/
â”‚  â”œâ”€ infer_image.py     # CLI: run on a single image or folder
â”‚  â””â”€ visualize.py       # CLI: draw polygons and save result
â””â”€ outputs/
   â”œâ”€ preds.jsonl        # one line per input {file, polys, scores}
   â””â”€ vis/               # rendered images with overlays

Layout 2
textcam_flask/
â”œâ”€ app.py                      # Flask app; creates global detector; exposes routes
â”œâ”€ detector/                   # re-use from Stage 1 (symlink/copy)
â”‚  â”œâ”€ config.py
â”‚  â””â”€ runner.py
â”œâ”€ templates/
â”‚  â””â”€ index.html               # video element + overlay canvas
â””â”€ static/
   â””â”€ app.js     


   ğŸ§ª How to run and test
From project root:
export FLASK_APP=webapp/app.py
python webapp/app.py
Open http://localhost:5000.
Click Start â†’ browser asks camera permission â†’ you should see boxes appear over text in view.

virtual env == mmocr-webapp

Now in a new machine/repo:
python -m venv venv
source venv/bin/activate   # (or .\venv\Scripts\activate on Windows)
pip install -r requirements.txt
